# 🧠 Remi - 本地 Gemini AI 助手

一个基于 Streamlit 的本地 AI 助手应用，集成 Memori 实现跨会话长期记忆，使用 Google Gemini 模型提供智能对话体验。

## ✨ 项目功能

### 核心特性

- **🤖 智能对话**：基于 Google Gemini 模型的自然语言对话
- **🧠 长期记忆**：使用 Memori 引擎实现跨会话的持久化记忆
- **🎭 自定义人设**：支持自定义 AI 助手的性格和行为方式
- **💬 现代化界面**：基于 Streamlit 的现代化聊天界面
- **🔄 记忆模式**：支持 Conscious、Auto 和 Combined 三种记忆模式
- **📊 记忆管理**：可视化记忆状态和最近记忆内容
- **🖼️ 头像定制**：支持用户和助手头像自定义
- **🌐 多语言支持**：支持中文和英文界面切换

### 记忆系统

- **短期记忆**：存储最近 7-30 天的对话内容，用于当前会话上下文
- **长期记忆**：永久存储重要的用户偏好、关键事实和技能信息
- **智能检索**：根据用户查询自动检索相关历史记忆
- **上下文注入**：自动将相关记忆注入到对话上下文中，提升回答质量

## 🚀 如何使用

### 环境要求

- **操作系统**：Windows 10/11
- **Python 版本**：3.14
- **Google API Key**：需要从 [Google AI Studio](https://makersuite.google.com/app/apikey) 获取 Gemini API Key

### 安装步骤

1. **克隆项目**
   ```bash
   git clone <repository-url>
   cd "Remi - Gemini Personal AI Assistant"
   ```

2. **安装依赖**
   ```bash
   pip install -r requirements.txt
   ```

3. **配置初始化文件（可选）**
   ```bash
   # 复制示例配置文件（如果不存在 config.json）
   copy config.json.example config.json
   # 或者手动创建 config.json 并填入你的配置
   ```

4. **运行应用**
   ```bash
   streamlit run app.py
   ```

5. **配置 API Key**
   - 应用启动后，点击左上角的设置按钮（⚙️）
   - 在侧边栏输入你的 Google Gemini API Key
   - 选择模型名称（默认为 `gemini-2.5-flash`）
   - 自定义 AI 人设（可选）
   - 点击"保存设置"

6. **开始对话**
   - 在底部输入框输入消息
   - AI 助手会自动检索相关记忆并生成个性化回复
   - 所有对话内容会自动存储到记忆系统中

### 使用技巧

- **记忆模式选择**：
  - **Conscious**：会话开始时注入关键记忆，响应速度快
  - **Auto**：每次查询动态检索相关记忆，上下文更精准
  - **Combined**：同时使用两种模式，获得最大智能度

- **记忆管理**：
  - 在侧边栏可以查看记忆状态和最近记忆
  - 记忆数据存储在 `local_memory.db` 文件中
  - 可以随时清除当前会话显示，但不会删除记忆数据

## 🛠️ 主要技术

### 前端框架
- **Streamlit** (>=1.28.0)：用于构建现代化 Web 界面

### LLM 集成
- **LangChain** (>=0.3.0)：LLM 编排框架
- **langchain-google-genai** (>=2.0.0)：Google Gemini 模型集成
- **Google Gemini**：核心语言模型（默认 gemini-2.5-flash）

### 记忆引擎
- **Memori**：开源记忆引擎，实现跨会话长期记忆
- **SQLite**：本地数据库存储（`local_memory.db`）

### 其他依赖
- **LiteLLM** (>=1.0.0)：Memori 内部 LLM 调用
- **SQLAlchemy** (>=2.0.0)：数据库 ORM
- **Pydantic** (>=2.0.0)：数据验证
- **Pillow** (>=10.0.0)：图像处理（头像功能）

## 📊 端侧 RAG 方法对比：SQL vs 向量化

本项目使用 Memori 的 SQL 原生方法实现 RAG（检索增强生成），相比传统的向量化方法具有显著优势：

### SQL 方法（本项目采用）

**技术实现**：
- 使用 SQLite FTS5 全文搜索引擎
- 基于关键词匹配和布尔逻辑查询
- 支持实体提取和分类存储
- 多因子排序（重要性、时间、类别）

**优势**：
- ✅ **成本低**：比向量数据库便宜 80-90%
- ✅ **速度快**：查询延迟 8-12ms，比向量搜索快 3 倍
- ✅ **可移植**：数据存储在标准 SQL 数据库，可导出为 `.db` 文件
- ✅ **可读性强**：SQL 查询透明可调试，便于问题排查
- ✅ **复杂查询**：支持完整的 SQL 功能（AND、OR、NOT 等布尔逻辑）
- ✅ **精确匹配**：适合明确的查询需求（如"我的技术栈是什么？"）

**适用场景**：
- 对话式 AI 记忆系统
- 用户偏好和事实存储
- 需要精确匹配的场景
- 成本敏感的应用

### 向量化方法

**技术实现**：
- 使用 embedding 模型将文本转换为向量
- 通过余弦相似度计算语义相似性
- 需要向量数据库（如 Pinecone、Weaviate）

**优势**：
- ✅ **语义理解**：能够理解同义词和语义相似性
- ✅ **模糊匹配**：适合"找到类似文档"的场景

**劣势**：
- ❌ **成本高**：100K 记忆约 $80-100/月
- ❌ **速度慢**：查询延迟 25-40ms
- ❌ **供应商锁定**：数据格式专有，难以迁移
- ❌ **黑盒操作**：embedding 过程不透明，难以调试
- ❌ **查询限制**：主要支持距离计算，复杂查询能力有限

**适用场景**：
- 非结构化文档的语义搜索
- 需要理解语义相似性的场景
- 大规模文档库检索

### 对比总结

| 特性 | SQL 方法（Memori） | 向量化方法 | 胜者 |
|------|-------------------|-----------|------|
| **成本（100K 记忆）** | $0-15/月 | $80-100/月 | **SQL 方法** |
| **查询速度** | 8-12ms | 25-40ms | **SQL 方法** |
| **可移植性** | 标准 SQL 格式 | 供应商锁定 | **SQL 方法** |
| **透明度** | 可读 SQL 查询 | 黑盒 embedding | **SQL 方法** |
| **复杂查询** | 完整 SQL 功能 | 距离计算为主 | **SQL 方法** |
| **语义理解** | 关键词匹配 | 语义相似性 | **向量化方法** |

**结论**：对于对话式 AI 记忆系统，90% 的查询都是明确的（如"我的技术栈是什么？"），SQL 方法在成本、速度、可移植性和透明度方面都更优，但在情感陪伴类ai中需要精心设计prompt工程。向量化方法更适合需要语义相似性搜索的非结构化文档场景，在情感陪伴类ai更为适合。

## 🙏 致谢

### Memori

本项目使用了 [Memori](https://github.com/GibsonAI/memori) 开源记忆引擎，这是一个强大的端侧 RAG 解决方案，提供了：

- SQL 原生的记忆存储和检索
- 智能的记忆分类和实体提取
- 多代理架构实现记忆的智能提升
- 支持多种数据库（SQLite、PostgreSQL、MySQL）

感谢 Memori 团队为开源社区贡献了如此优秀的记忆引擎！

### Google

感谢 Google 提供的 Gemini 模型和 API 服务，使得本项目能够提供高质量的 AI 对话体验。

- [Google AI Studio](https://makersuite.google.com/app/apikey)
- [Gemini API 文档](https://ai.google.dev/docs)

## 📧 联系方式

如有问题、建议或合作意向，欢迎联系：

- **Email**：576233187@qq.com
- **微信**：liuyouzhenn

## 📝 许可证

本项目基于 Memori 开源项目构建，请遵循相应的开源许可证。

---

**Made with ❤️ for developers who want their AI agents to remember and learn**

